{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Otfj8hsnJNy"
      },
      "source": [
        "# HSE 2022: Mathematical Methods for Data Analysis\n",
        "\n",
        "## Homework 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-26T16:48:20.566549Z",
          "start_time": "2020-09-26T16:48:19.893995Z"
        },
        "id": "h2Dqv_5InJN0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLSResults\n",
        "import math\n",
        "from math import sqrt\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLzfoSp2nJN1"
      },
      "source": [
        "### Data\n",
        "\n",
        "For this homework we use Dataset from seaborn on diamonds prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OcrKycsJnJN1"
      },
      "outputs": [],
      "source": [
        "data = sns.load_dataset('diamonds')\n",
        "\n",
        "y = data.price\n",
        "X = data.drop(['price'], axis=1)\n",
        "columns = data.drop(['price'], axis=1).columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxT6HlAonJN2"
      },
      "source": [
        "## Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ZIp3-CnJN2"
      },
      "source": [
        "#### 0. [0.25 points] Encode categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e8pyIlCqnJN2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4a759b1d-9d3b-444d-a14c-2019367677ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   carat      cut color clarity  depth  table     x     y     z\n",
              "0   0.23    Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
              "1   0.21  Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
              "2   0.23     Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
              "3   0.29  Premium     I     VS2   62.4   58.0  4.20  4.23  2.63\n",
              "4   0.31     Good     J     SI2   63.3   58.0  4.34  4.35  2.75"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fed693cc-40d7-494b-bd78-bcea1ff83be1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>E</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>Premium</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>Good</td>\n",
              "      <td>E</td>\n",
              "      <td>VS1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>Premium</td>\n",
              "      <td>I</td>\n",
              "      <td>VS2</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>Good</td>\n",
              "      <td>J</td>\n",
              "      <td>SI2</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed693cc-40d7-494b-bd78-bcea1ff83be1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fed693cc-40d7-494b-bd78-bcea1ff83be1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fed693cc-40d7-494b-bd78-bcea1ff83be1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.cut.unique())\n",
        "print(X.color.unique())\n",
        "print(X.clarity.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KOtmxiMd3nv",
        "outputId": "177b9d79-5d5d-452c-c308-c5d1eb2df850"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ideal', 'Premium', 'Good', 'Very Good', 'Fair']\n",
            "Categories (5, object): ['Ideal', 'Premium', 'Very Good', 'Good', 'Fair']\n",
            "['E', 'I', 'J', 'H', 'F', 'G', 'D']\n",
            "Categories (7, object): ['D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
            "['SI2', 'SI1', 'VS1', 'VS2', 'VVS2', 'VVS1', 'I1', 'IF']\n",
            "Categories (8, object): ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'I1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Cut\n",
        "\n",
        "Значения категориальной переменной являются порядковыми: Very good лучше, чем Good => используем Label Encoding\n",
        "\n",
        "2) Color\n",
        "\n",
        "Значения категориальной переменной являются порядковыми: J - худший, D - лучший => Label Encoding\n",
        "\n",
        "3) Clarity\n",
        "\n",
        "=> One Hot Encoding\n"
      ],
      "metadata": {
        "id": "9ZX36NHYigNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "X.color = encoder.fit_transform(X.color)\n",
        "X.color.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXZsEsi6d9ds",
        "outputId": "cee59b1e-c245-48f4-d36f-beca2e42b385"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 5, 6, 4, 2, 3, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.cut = encoder.fit_transform(X.cut)\n",
        "X.cut.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Go-mjCni-D",
        "outputId": "45b9d19b-baf8-4aca-82ec-268a5acbd33f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 1, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(data=X, columns=['clarity'], drop_first = True)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "58suBg3pnqt-",
        "outputId": "3b777a96-6931-49ff-95ec-0cc017cb361a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   carat  cut  color  depth  table     x     y     z  clarity_VVS1  \\\n",
              "0   0.23    2      1   61.5   55.0  3.95  3.98  2.43             0   \n",
              "1   0.21    3      1   59.8   61.0  3.89  3.84  2.31             0   \n",
              "2   0.23    1      1   56.9   65.0  4.05  4.07  2.31             0   \n",
              "3   0.29    3      5   62.4   58.0  4.20  4.23  2.63             0   \n",
              "4   0.31    1      6   63.3   58.0  4.34  4.35  2.75             0   \n",
              "\n",
              "   clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \\\n",
              "0             0            0            0            0            1   \n",
              "1             0            0            0            1            0   \n",
              "2             0            1            0            0            0   \n",
              "3             0            0            1            0            0   \n",
              "4             0            0            0            0            1   \n",
              "\n",
              "   clarity_I1  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4ff8ca1-dcaf-4be5-b0c9-55272320d3e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <th>clarity_VVS2</th>\n",
              "      <th>clarity_VS1</th>\n",
              "      <th>clarity_VS2</th>\n",
              "      <th>clarity_SI1</th>\n",
              "      <th>clarity_SI2</th>\n",
              "      <th>clarity_I1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4ff8ca1-dcaf-4be5-b0c9-55272320d3e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4ff8ca1-dcaf-4be5-b0c9-55272320d3e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4ff8ca1-dcaf-4be5-b0c9-55272320d3e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2TBc5uZnJN2"
      },
      "source": [
        "#### 1. [0.25 points] Split the data into train and test sets with ratio 80:20 with random_state=17."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fj5aCV0znJN3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3OsMOgnnJN3"
      },
      "source": [
        "#### 2. [1 point] Train models on train data using StatsModels library and apply it to the test set; use $RMSE$ and $R^2$ as the quality measure.\n",
        "\n",
        "* [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html);\n",
        "* [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) with $\\alpha = 0.01$;\n",
        "* [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) with $\\alpha = 0.01$\n",
        "* [`ElasticNet`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) with $\\alpha = 0.01$, $l_{1}$_$ratio = 0.6$\n",
        "\n",
        "Don't forget to scale the data before training the models with StandardScaler!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iLD7OomEnJN4"
      },
      "outputs": [],
      "source": [
        "# Scale the data before training\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Add the constant term to the data\n",
        "X_train_scaled = sm.add_constant(X_train_scaled)\n",
        "X_test_scaled = sm.add_constant(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression\n",
        "linear_regression = sm.OLS(y_train, X_train_scaled)\n",
        "linear_regression = linear_regression.fit()\n",
        "lr_pred = linear_regression.predict(X_test_scaled)\n",
        "\n",
        "# RMSE\n",
        "lr_rmse = mean_squared_error(y_test, lr_pred, squared = False)\n",
        "#R2\n",
        "lr_r2 = r2_score(y_test, lr_pred)\n",
        "print(f'Linear Regression: RMSE {lr_rmse} R2:{lr_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbeb4GRnN0dL",
        "outputId": "9b6a2606-20ff-48d0-fde4-8a91f68f4828"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression: RMSE 1178.9960913215941 R2:0.9141617585330128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Ridge Regression\n",
        "ridge_regression = sm.OLS(y_train, X_train_scaled)\n",
        "ridge_results_fu = ridge_regression.fit()\n",
        "ridge_results_fr = ridge_regression.fit_regularized(L1_wt=0, alpha=0.01, start_params=ridge_results_fu.params)\n",
        "    \n",
        "ridge_results = OLSResults(model=ridge_regression, \n",
        "                                             params=ridge_results_fr.params, \n",
        "                                             normalized_cov_params=ridge_regression.normalized_cov_params)\n",
        "r_pred = ridge_results.predict(X_test_scaled)\n",
        "\n",
        "# RMSE\n",
        "r_rmse = mean_squared_error(y_test, r_pred, squared = False)\n",
        "#R2\n",
        "r_r2 = r2_score(y_test, r_pred)\n",
        "print(f'Ridge Regression: RMSE {r_rmse} R2:{r_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn4EkwoNN-AN",
        "outputId": "16b6dd79-d8f3-4548-d9a1-cee3b9b0fa7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression: RMSE 1191.7519796009808 R2:0.9122942947243566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Lasso Regression\n",
        "lasso_regression = sm.OLS(y_train, X_train_scaled)\n",
        "lasso_results_fu = lasso_regression.fit()\n",
        "lasso_results_fr = lasso_regression.fit_regularized(L1_wt=1, alpha=0.01, start_params=lasso_results_fu.params)\n",
        "    \n",
        "lasso_results = OLSResults(model=lasso_regression, \n",
        "                                             params=lasso_results_fr.params, \n",
        "                                             normalized_cov_params=lasso_regression.normalized_cov_params)\n",
        "l_pred = lasso_results.predict(X_test_scaled)\n",
        "\n",
        "# RMSE\n",
        "l_rmse = mean_squared_error(y_test, l_pred, squared = False)\n",
        "#R2\n",
        "l_r2 = r2_score(y_test, l_pred)\n",
        "print(f'Lasso Regression: RMSE {l_rmse} R2:{l_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY1UeWU4O5_3",
        "outputId": "55f97b5d-c32a-46c8-d003-f7304b1a230f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Regression: RMSE 1178.9915936859898 R2:0.9141624134434022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Elastic Net Regression\n",
        "elastic_net_regression = sm.OLS(y_train, X_train_scaled)\n",
        "elastic_net_results_fu = elastic_net_regression.fit()\n",
        "elastic_net_results_fr = elastic_net_regression.fit_regularized(method='elastic_net', \n",
        "                                                        L1_wt= 0.6, \n",
        "                                                        alpha=0.01, \n",
        "                                                        start_params=elastic_net_results_fu.params)\n",
        "     \n",
        "elastic_net_results = OLSResults(model=elastic_net_regression, \n",
        "                                    params=elastic_net_results_fr.params, \n",
        "                                    normalized_cov_params=elastic_net_regression.normalized_cov_params)\n",
        "en_pred = elastic_net_results.predict(X_test_scaled)\n",
        "\n",
        "# RMSE\n",
        "en_rmse = mean_squared_error(y_test, en_pred, squared = False)\n",
        "#R2\n",
        "en_r2 = r2_score(y_test, en_pred)\n",
        "print(f'Elastic Net Regression: RMSE {en_rmse} R2:{en_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFbHaPD9P-41",
        "outputId": "3d5aa629-2b14-43ed-8500-14dadedc5c81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Regression: RMSE 1178.3400414740106 R2:0.9142572609654591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6QNTxBanJN4"
      },
      "source": [
        "#### 3. [1 point] Explore the values of the parameters of the resulting models and compare the number of zero weights in them. Comment on the significance of the coefficients, overal model significance and other related factors from the results table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7WOXYSDQnJN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094a44bf-fb16-4337-909e-c37e9776c3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression\n",
            "\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.916\n",
            "Model:                            OLS   Adj. R-squared:                  0.916\n",
            "Method:                 Least Squares   F-statistic:                 3.147e+04\n",
            "Date:                Sun, 16 Oct 2022   Prob (F-statistic):               0.00\n",
            "Time:                        13:18:34   Log-Likelihood:            -3.6542e+05\n",
            "No. Observations:               43152   AIC:                         7.309e+05\n",
            "Df Residuals:                   43136   BIC:                         7.310e+05\n",
            "Df Model:                          15                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       3928.6813      5.546    708.354      0.000    3917.811    3939.552\n",
            "x1          5310.4649     26.736    198.626      0.000    5258.062    5362.868\n",
            "x2            56.2076      5.712      9.840      0.000      45.011      67.404\n",
            "x3          -551.4766      5.890    -93.627      0.000    -563.021    -539.932\n",
            "x4          -144.9206      6.843    -21.177      0.000    -158.334    -131.508\n",
            "x5          -133.9661      6.015    -22.271      0.000    -145.756    -122.176\n",
            "x6         -1110.5048     41.525    -26.743      0.000   -1191.894   -1029.116\n",
            "x7             7.0641     25.226      0.280      0.779     -42.380      56.508\n",
            "x8           -47.6862     25.340     -1.882      0.060     -97.354       1.981\n",
            "x9           -97.6775      9.317    -10.484      0.000    -115.939     -79.416\n",
            "x10         -138.9692     10.308    -13.482      0.000    -159.173    -118.766\n",
            "x11         -315.5046     12.134    -26.002      0.000    -339.287    -291.722\n",
            "x12         -507.6055     13.806    -36.767      0.000    -534.666    -480.545\n",
            "x13         -784.3414     14.142    -55.461      0.000    -812.060    -756.623\n",
            "x14        -1048.8520     12.920    -81.179      0.000   -1074.176   -1023.528\n",
            "x15         -637.2208      6.695    -95.185      0.000    -650.342    -624.099\n",
            "==============================================================================\n",
            "Omnibus:                    10872.169   Durbin-Watson:                   1.997\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           300680.586\n",
            "Skew:                           0.611   Prob(JB):                         0.00\n",
            "Kurtosis:                      15.874   Cond. No.                         17.9\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "******************************************\n",
            "\n",
            "Ridge Regression\n",
            "\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.913\n",
            "Model:                            OLS   Adj. R-squared:                  0.913\n",
            "Method:                 Least Squares   F-statistic:                 3.023e+04\n",
            "Date:                Sun, 16 Oct 2022   Prob (F-statistic):               0.00\n",
            "Time:                        13:18:34   Log-Likelihood:            -3.6621e+05\n",
            "No. Observations:               43152   AIC:                         7.324e+05\n",
            "Df Residuals:                   43136   BIC:                         7.326e+05\n",
            "Df Model:                          15                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       3889.7835      5.649    688.606      0.000    3878.712    3900.855\n",
            "x1          4291.0414     27.230    157.583      0.000    4237.669    4344.414\n",
            "x2            61.7034      5.818     10.606      0.000      50.300      73.107\n",
            "x3          -515.4231      5.999    -85.917      0.000    -527.181    -503.665\n",
            "x4           -91.8686      6.970    -13.181      0.000    -105.530     -78.208\n",
            "x5          -128.9998      6.127    -21.056      0.000    -141.008    -116.992\n",
            "x6          -137.5512     42.293     -3.252      0.001    -220.445     -54.657\n",
            "x7            18.5330     25.693      0.721      0.471     -31.825      68.891\n",
            "x8           -53.1194     25.809     -2.058      0.040    -103.705      -2.533\n",
            "x9           -22.3875      9.489     -2.359      0.018     -40.987      -3.788\n",
            "x10          -57.9479     10.498     -5.520      0.000     -78.525     -37.371\n",
            "x11         -227.6046     12.358    -18.417      0.000    -251.827    -203.382\n",
            "x12         -399.8608     14.061    -28.437      0.000    -427.421    -372.300\n",
            "x13         -681.6624     14.404    -47.326      0.000    -709.894    -653.431\n",
            "x14         -939.1002     13.159    -71.365      0.000    -964.892    -913.308\n",
            "x15         -590.1629      6.818    -86.555      0.000    -603.527    -576.799\n",
            "==============================================================================\n",
            "Omnibus:                    13255.629   Durbin-Watson:                   1.995\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           146856.469\n",
            "Skew:                           1.158   Prob(JB):                         0.00\n",
            "Kurtosis:                      11.736   Cond. No.                         17.9\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "******************************************\n",
            "\n",
            "Lasso Regression\n",
            "\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.916\n",
            "Model:                            OLS   Adj. R-squared:                  0.916\n",
            "Method:                 Least Squares   F-statistic:                 3.147e+04\n",
            "Date:                Sun, 16 Oct 2022   Prob (F-statistic):               0.00\n",
            "Time:                        13:18:34   Log-Likelihood:            -3.6542e+05\n",
            "No. Observations:               43152   AIC:                         7.309e+05\n",
            "Df Residuals:                   43136   BIC:                         7.310e+05\n",
            "Df Model:                          15                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       3928.6713      5.546    708.353      0.000    3917.801    3939.542\n",
            "x1          5310.1659     26.736    198.615      0.000    5257.763    5362.569\n",
            "x2            56.1983      5.712      9.838      0.000      45.002      67.395\n",
            "x3          -551.4501      5.890    -93.622      0.000    -562.995    -539.905\n",
            "x4          -144.9157      6.843    -21.176      0.000    -158.329    -131.503\n",
            "x5          -133.9602      6.015    -22.270      0.000    -145.750    -122.170\n",
            "x6         -1109.9735     41.525    -26.730      0.000   -1191.363   -1028.584\n",
            "x7             6.6971     25.226      0.265      0.791     -42.747      56.141\n",
            "x8           -47.5817     25.340     -1.878      0.060     -97.249       2.086\n",
            "x9           -97.5017      9.317    -10.465      0.000    -115.763     -79.240\n",
            "x10         -138.7681     10.308    -13.462      0.000    -158.972    -118.565\n",
            "x11         -315.2635     12.134    -25.982      0.000    -339.046    -291.481\n",
            "x12         -507.3233     13.806    -36.746      0.000    -534.383    -480.263\n",
            "x13         -784.0562     14.142    -55.441      0.000    -811.775    -756.337\n",
            "x14        -1048.5931     12.920    -81.159      0.000   -1073.917   -1023.269\n",
            "x15         -637.1334      6.695    -95.172      0.000    -650.255    -624.012\n",
            "==============================================================================\n",
            "Omnibus:                    10873.749   Durbin-Watson:                   1.997\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           300654.500\n",
            "Skew:                           0.611   Prob(JB):                         0.00\n",
            "Kurtosis:                      15.873   Cond. No.                         17.9\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "******************************************\n",
            "\n",
            "Elastic Net Regression\n",
            "\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.916\n",
            "Model:                            OLS   Adj. R-squared:                  0.916\n",
            "Method:                 Least Squares   F-statistic:                 3.122e+04\n",
            "Date:                Sun, 16 Oct 2022   Prob (F-statistic):               0.00\n",
            "Time:                        13:18:34   Log-Likelihood:            -3.6557e+05\n",
            "No. Observations:               43152   AIC:                         7.312e+05\n",
            "Df Residuals:                   43136   BIC:                         7.313e+05\n",
            "Df Model:                          15                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       3913.0232      5.567    702.956      0.000    3902.113    3923.934\n",
            "x1          4862.5689     26.834    181.210      0.000    4809.974    4915.164\n",
            "x2            58.9326      5.733     10.279      0.000      47.695      70.170\n",
            "x3          -535.7335      5.912    -90.622      0.000    -547.321    -524.146\n",
            "x4          -117.5962      6.868    -17.121      0.000    -131.058    -104.134\n",
            "x5          -132.0620      6.037    -21.874      0.000    -143.895    -120.229\n",
            "x6          -612.3052     41.677    -14.692      0.000    -693.992    -530.618\n",
            "x7           -23.7320     25.319     -0.937      0.349     -73.357      25.893\n",
            "x8           -84.2608     25.433     -3.313      0.001    -134.110     -34.411\n",
            "x9           -63.5107      9.351     -6.792      0.000     -81.839     -45.182\n",
            "x10         -102.3121     10.346     -9.889      0.000    -122.590     -82.035\n",
            "x11         -275.9369     12.178    -22.658      0.000    -299.807    -252.067\n",
            "x12         -459.4662     13.857    -33.159      0.000    -486.625    -432.307\n",
            "x13         -738.7519     14.194    -52.047      0.000    -766.572    -710.932\n",
            "x14        -1000.7075     12.968    -77.170      0.000   -1026.124    -975.291\n",
            "x15         -617.0104      6.719    -91.830      0.000    -630.180    -603.841\n",
            "==============================================================================\n",
            "Omnibus:                    12044.329   Durbin-Watson:                   1.996\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           215599.904\n",
            "Skew:                           0.883   Prob(JB):                         0.00\n",
            "Kurtosis:                      13.807   Cond. No.                         17.9\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "print('Linear Regression\\n')\n",
        "print(linear_regression.summary())\n",
        "print('\\n******************************************\\n')\n",
        "\n",
        "print('Ridge Regression\\n')\n",
        "print(ridge_results.summary())\n",
        "print('\\n******************************************\\n')\n",
        "\n",
        "print('Lasso Regression\\n')\n",
        "print(lasso_results.summary())\n",
        "print('\\n******************************************\\n')\n",
        "\n",
        "print('Elastic Net Regression\\n')\n",
        "print(elastic_net_results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make conclusions**\n",
        "\n",
        "R2 for all models is about the same\n",
        "\n",
        "At the significance level of the model 0, all models are significant (their Prob = 0)\n",
        "\n",
        "x7 and x8 in all models have the value closest to 0, their P-value is the highest => they have the least impact on the result"
      ],
      "metadata": {
        "id": "xI189FNaVEo1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM2eUK8LnJN4"
      },
      "source": [
        "#### 4. [1 point] Implement one of the elimination algorithms that were described in the Seminar_4 (Elimination by P-value, Forward elimination, Backward elimination), make conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "V7IzNHfqnJN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33958a37-3199-4f43-a80a-f62535c6d43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Results: Ordinary least squares\n",
            "====================================================================\n",
            "Model:              OLS              Adj. R-squared:     0.916      \n",
            "Dependent Variable: price            AIC:                730863.7495\n",
            "Date:               2022-10-16 15:02 BIC:                731002.5093\n",
            "No. Observations:   43152            Log-Likelihood:     -3.6542e+05\n",
            "Df Model:           15               F-statistic:        3.147e+04  \n",
            "Df Residuals:       43136            Prob (F-statistic): 0.00       \n",
            "R-squared:          0.916            Scale:              1.3274e+06 \n",
            "---------------------------------------------------------------------\n",
            "         Coef.     Std.Err.     t      P>|t|     [0.025      0.975]  \n",
            "---------------------------------------------------------------------\n",
            "const   3928.6813    5.5462  708.3543  0.0000   3917.8106   3939.5520\n",
            "x1      5310.4649   26.7360  198.6260  0.0000   5258.0618   5362.8680\n",
            "x2        56.2076    5.7123    9.8398  0.0000     45.0113     67.4038\n",
            "x3      -551.4766    5.8902  -93.6269  0.0000   -563.0214   -539.9318\n",
            "x4      -144.9206    6.8433  -21.1770  0.0000   -158.3336   -131.5076\n",
            "x5      -133.9661    6.0153  -22.2708  0.0000   -145.7562   -122.1760\n",
            "x6     -1110.5048   41.5246  -26.7433  0.0000  -1191.8939  -1029.1158\n",
            "x7         7.0641   25.2263    0.2800  0.7795    -42.3799     56.5081\n",
            "x8       -47.6862   25.3403   -1.8818  0.0599    -97.3537      1.9813\n",
            "x9       -97.6775    9.3169  -10.4839  0.0000   -115.9388    -79.4161\n",
            "x10     -138.9692   10.3078  -13.4819  0.0000   -159.1727   -118.7657\n",
            "x11     -315.5046   12.1339  -26.0019  0.0000   -339.2873   -291.7220\n",
            "x12     -507.6055   13.8061  -36.7668  0.0000   -534.6656   -480.5453\n",
            "x13     -784.3414   14.1421  -55.4614  0.0000   -812.0602   -756.6226\n",
            "x14    -1048.8520   12.9202  -81.1791  0.0000  -1074.1759  -1023.5281\n",
            "x15     -637.2208    6.6945  -95.1855  0.0000   -650.3422   -624.0995\n",
            "--------------------------------------------------------------------\n",
            "Omnibus:            10872.169      Durbin-Watson:         1.997     \n",
            "Prob(Omnibus):      0.000          Jarque-Bera (JB):      300680.586\n",
            "Skew:               0.611          Prob(JB):              0.000     \n",
            "Kurtosis:           15.874         Condition No.:         18        \n",
            "====================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Elimination by P-value on the simple linear regression model\n",
        "# Def for convenient column deletion\n",
        "def eliminationByPValue(values):\n",
        "    reg = sm.OLS(y_train, X_train_scaled[:, values] ).fit()\n",
        "    reg_pred = reg.predict(X_test_scaled[:, values])\n",
        "    print(reg.summary2())\n",
        "\n",
        "\n",
        "# All features\n",
        "eliminationByPValue([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x7 has the highest P-value\n",
        "eliminationByPValue([0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Hs9l7MCsHC",
        "outputId": "a21f0b92-0c01-41fe-ec0e-6a285e44a931"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Results: Ordinary least squares\n",
            "====================================================================\n",
            "Model:              OLS              Adj. R-squared:     0.916      \n",
            "Dependent Variable: price            AIC:                730861.8280\n",
            "Date:               2022-10-16 15:03 BIC:                730991.9152\n",
            "No. Observations:   43152            Log-Likelihood:     -3.6542e+05\n",
            "Df Model:           14               F-statistic:        3.371e+04  \n",
            "Df Residuals:       43137            Prob (F-statistic): 0.00       \n",
            "R-squared:          0.916            Scale:              1.3273e+06 \n",
            "---------------------------------------------------------------------\n",
            "         Coef.     Std.Err.     t      P>|t|     [0.025      0.975]  \n",
            "---------------------------------------------------------------------\n",
            "const   3928.6813    5.5462  708.3619  0.0000   3917.8107   3939.5518\n",
            "x1      5310.7614   26.7147  198.7952  0.0000   5258.4000   5363.1228\n",
            "x2        56.2421    5.7109    9.8482  0.0000     45.0486     67.4355\n",
            "x3      -551.4801    5.8901  -93.6287  0.0000   -563.0247   -539.9354\n",
            "x4      -145.0832    6.8185  -21.2778  0.0000   -158.4477   -131.7188\n",
            "x5      -134.0263    6.0114  -22.2953  0.0000   -145.8088   -122.2439\n",
            "x6     -1104.7294   36.0401  -30.6527  0.0000  -1175.3687  -1034.0900\n",
            "x7       -46.8230   25.1518   -1.8616  0.0627    -96.1210      2.4751\n",
            "x8       -97.6863    9.3168  -10.4850  0.0000   -115.9474    -79.4253\n",
            "x9      -138.9772   10.3077  -13.4829  0.0000   -159.1804   -118.7740\n",
            "x10     -315.5202   12.1336  -26.0038  0.0000   -339.3024   -291.7381\n",
            "x11     -507.6321   13.8056  -36.7700  0.0000   -534.6913   -480.5729\n",
            "x12     -784.3618   14.1418  -55.4642  0.0000   -812.0800   -756.6437\n",
            "x13    -1048.8696   12.9199  -81.1822  0.0000  -1074.1929  -1023.5462\n",
            "x14     -637.2522    6.6935  -95.2046  0.0000   -650.3716   -624.1328\n",
            "--------------------------------------------------------------------\n",
            "Omnibus:            10871.661      Durbin-Watson:         1.997     \n",
            "Prob(Omnibus):      0.000          Jarque-Bera (JB):      300760.514\n",
            "Skew:               0.611          Prob(JB):              0.000     \n",
            "Kurtosis:           15.876         Condition No.:         15        \n",
            "====================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x8 in first model has the highest P-value\n",
        "eliminationByPValue([0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yK1wzJfF4sg",
        "outputId": "64552d3a-619f-4b8e-aab9-d07935c16349"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Results: Ordinary least squares\n",
            "====================================================================\n",
            "Model:              OLS              Adj. R-squared:     0.916      \n",
            "Dependent Variable: price            AIC:                730863.2946\n",
            "Date:               2022-10-16 15:03 BIC:                730984.7094\n",
            "No. Observations:   43152            Log-Likelihood:     -3.6542e+05\n",
            "Df Model:           13               F-statistic:        3.631e+04  \n",
            "Df Residuals:       43138            Prob (F-statistic): 0.00       \n",
            "R-squared:          0.916            Scale:              1.3274e+06 \n",
            "---------------------------------------------------------------------\n",
            "         Coef.     Std.Err.     t      P>|t|     [0.025      0.975]  \n",
            "---------------------------------------------------------------------\n",
            "const   3928.6813    5.5463  708.3416  0.0000   3917.8104   3939.5522\n",
            "x1      5310.1223   26.7133  198.7820  0.0000   5257.7638   5362.4809\n",
            "x2        56.0450    5.7101    9.8151  0.0000     44.8531     67.2369\n",
            "x3      -551.4050    5.8901  -93.6155  0.0000   -562.9497   -539.8603\n",
            "x4      -150.6239    6.1348  -24.5522  0.0000   -162.6483   -138.5995\n",
            "x5      -133.8016    6.0104  -22.2618  0.0000   -145.5821   -122.0212\n",
            "x6     -1149.6967   26.7482  -42.9822  0.0000  -1202.1237  -1097.2698\n",
            "x7       -97.6357    9.3170  -10.4793  0.0000   -115.8971    -79.3742\n",
            "x8      -138.9188   10.3079  -13.4769  0.0000   -159.1225   -118.7152\n",
            "x9      -315.5328   12.1340  -26.0040  0.0000   -339.3156   -291.7499\n",
            "x10     -507.4836   13.8058  -36.7588  0.0000   -534.5432   -480.4241\n",
            "x11     -784.1947   14.1419  -55.4519  0.0000   -811.9131   -756.4763\n",
            "x12    -1048.6973   12.9200  -81.1687  0.0000  -1074.0207  -1023.3739\n",
            "x13     -637.0316    6.6926  -95.1838  0.0000   -650.1493   -623.9139\n",
            "--------------------------------------------------------------------\n",
            "Omnibus:            10871.186      Durbin-Watson:         1.997     \n",
            "Prob(Omnibus):      0.000          Jarque-Bera (JB):      300997.262\n",
            "Skew:               0.610          Prob(JB):              0.000     \n",
            "Kurtosis:           15.881         Condition No.:         11        \n",
            "====================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make conclusions**\n",
        "\n",
        "R2 did not change from model to model, we will be guided by AIC (the smaller it is, the better)\n",
        "\n",
        "After removing x7, it dropped a little => the model improved, after removing the second one, it almost returned to its previous value\n",
        "\n",
        "Since the P-value of x7 is significantly greater than that of x8, they affect the model differently\n",
        "\n",
        "The conducted research confirms that x7 is the sign with the least influence, it can be removed (y, the width of the diamond almost does not affect its price)\n",
        "\n",
        "x8 still has an impact on the model (its P-value is only 0.0599, at the significance level of 6% it is already significant), it should not be removed (the depth of the diamond is important)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xzCFloagjEpQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krhX1JoOnJN5"
      },
      "source": [
        "#### 5. [1 point] Find the best (in terms of RMSE) $\\alpha$ for Lasso regression using cross-validation with 4 folds. You must select values from range $[10^{-4}, 10^{3}]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sUQ12t-4nJN5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "e9df43d6-2ed4-4b55-a068-bf2823040ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha = 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CV score')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "alphas = np.logspace(-4, 3)\n",
        "searcher = GridSearchCV(Lasso(), [{\"alpha\": alphas}], scoring=\"neg_mean_squared_error\", cv=4)\n",
        "searcher.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best alpha = %.4f\" % searcher.best_params_[\"alpha\"])\n",
        "\n",
        "plt.plot(alphas, -searcher.cv_results_[\"mean_test_score\"])\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"CV score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2Z7mHBnJN5"
      },
      "source": [
        "## Gradient descent\n",
        "\n",
        "#### 6. [3.5 points] Implement a Ridge regression model for the MSE loss function, trained by gradient descent.\n",
        "\n",
        "All calculations must be vectorized, and python loops can only be used for gradient descent iterations. As a stop criterion, you must use (simultaneously):\n",
        "\n",
        "* checking for the Absolute-value norm of the weight difference on two adjacent iterations (for example, less than some small number of the order of $10^{-6}$, set by the `tolerance` parameter);\n",
        "* reaching the maximum number of iterations (for example, 10000, set by the `max_iter` parameter).\n",
        "\n",
        "You need to implement:\n",
        "\n",
        "* Full gradient descent:\n",
        "\n",
        "$$\n",
        "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} Q(w_{k}).\n",
        "$$\n",
        "\n",
        "* Stochastic Gradient Descent:\n",
        "\n",
        "$$\n",
        "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} q_{i_{k}}(w_{k}).\n",
        "$$\n",
        "\n",
        "$\\nabla_{w} q_{i_{k}}(w_{k}) \\, $ is the estimate of the gradient over the batch of objects selected randomly.\n",
        "\n",
        "* Momentum method:\n",
        "\n",
        "$$\n",
        "h_0 = 0, \\\\\n",
        "h_{k + 1} = \\alpha h_{k} + \\eta_k \\nabla_{w} Q(w_{k}), \\\\\n",
        "w_{k + 1} = w_{k} - h_{k + 1}.\n",
        "$$\n",
        "\n",
        "* Adagrad method:\n",
        "\n",
        "$$\n",
        "G_0 = 0, \\\\\n",
        "G_{k + 1} = G_{k} + (\\nabla_{w} Q(w_{k+1}))^2, \\\\\n",
        "w_{k + 1} = w_{k} - \\eta * \\frac{\\nabla_{w} Q(w_{k+1})}{\\sqrt{G_{k+1} + \\epsilon}}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "To make sure that the optimization process really converges, we will use the `loss_history` class attribute. After calling the `fit` method, it should contain the values of the loss function for all iterations, starting from the first one (before the first step on the anti-gradient).\n",
        "\n",
        "You need to initialize the weights with a random vector from normal distribution. The following is a template class that needs to contain the code implementing all variations of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "bYP5_kdhnJN6"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinReg(BaseEstimator):\n",
        "    def __init__(self, delta=1.0, gd_type='Momentum', \n",
        "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2, alpha=1e-3,\n",
        "                 reg_cf=0.01, epsilon=0.001):\n",
        "        \"\"\"\n",
        "        gd_type: str\n",
        "            'GradientDescent', 'StochasticDescent', 'Momentum', 'Adagrad'\n",
        "        delta: float\n",
        "            proportion of object in a batch (for stochastic GD)\n",
        "        tolerance: float\n",
        "            for stopping gradient descent\n",
        "        max_iter: int\n",
        "            maximum number of steps in gradient descent\n",
        "        w0: np.array of shape (d)\n",
        "            init weights\n",
        "        eta: float\n",
        "            learning rate\n",
        "        alpha: float\n",
        "            momentum coefficient\n",
        "        reg_cf: float\n",
        "            regularization coefficient\n",
        "        epsilon: float\n",
        "            numerical stability\n",
        "        \"\"\" \n",
        "        self.delta = delta\n",
        "        self.gd_type = gd_type\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.w0 = w0\n",
        "        self.w_prev = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.eta = eta\n",
        "        self.loss_history = None # list of loss function values at each training iteration\n",
        "        self.reg_cf = reg_cf\n",
        "        self.epsilon = epsilon\n",
        "        self.h = 0\n",
        "        self.G = 0\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        self.loss_history = []\n",
        "        y = np.array(y)\n",
        "        self.w = np.random.normal(0, 1, X.shape[1])\n",
        "        if self.w_prev is None:\n",
        "            self.w_prev = np.zeros(X.shape[1])\n",
        "        \n",
        "        for i in range(self.max_iter):\n",
        "            if self.tolerance > np.linalg.norm(self.w_prev - self.w):\n",
        "                break\n",
        "            self.w_prev = self.w\n",
        "            if self.gd_type == 'GradientDescent':\n",
        "                weight = self.full_gradient_descent(X, y)\n",
        "            elif self.gd_type == 'StochasticDescent': \n",
        "                weight = self.stochastic_descent(X, y)\n",
        "            elif self.gd_type == 'Momentum': \n",
        "                weight = self.momentum(X, y)\n",
        "            elif self.gd_type == 'Adagrad': \n",
        "                weight = self.adagrad(X, y)\n",
        "            else:\n",
        "                raise Exception('WRONG TYPE')\n",
        "            self.w = weight\n",
        "            self.loss_history.append(self.calc_loss(X, y))        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        return X.dot(self.w.T)\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: np.array of shape (d)\n",
        "        \"\"\"\n",
        "        return 2 * np.dot(X.T, self.predict(X) - y) / X.shape[0] + 2 * np.dot(self.reg_cf, self.w)\n",
        "\n",
        "    def calc_loss(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: float \n",
        "        \"\"\" \n",
        "        return mean_squared_error(y, self.predict(X))\n",
        "\n",
        "    def full_gradient_descent(self, X, y):\n",
        "        return self.w - np.dot(self.eta, self.calc_gradient(X, y))\n",
        "        \n",
        "    def stochastic_descent(self, X, y):\n",
        "        batch = np.random.randint(0, len(X), math.floor(self.delta * len(X)))\n",
        "        batch_x = X[batch, :]\n",
        "        batch_y = y[batch]\n",
        "        return self.w - np.dot(self.eta, self.calc_gradient(batch_x, batch_y))\n",
        "        \n",
        "    def momentum(self, X, y):\n",
        "        self.h = self.alpha * self.h + self.eta* self.calc_gradient(X, y)\n",
        "        return self.w - self.h\n",
        "    \n",
        "    def adagrad(self, X, y):\n",
        "        self.G = self.G + np.square(self.calc_gradient(X, y))\n",
        "        return self.w - self.eta * self.calc_gradient(X, y) / np.sqrt(self.G + self.epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvPf51mAnJN6"
      },
      "source": [
        "#### 7. [1 points] Train and validate \"hand-written\" models on the same data, and compare the quality with the Sklearn or StatsModels methods. Investigate the effect of the `max_iter` and `alpha` parameters on the optimization process. Is it consistent with your expectations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "lqLxLLhQnJN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89477939-076a-492c-8b28-9aac6d632280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression: RMSE 1178.9960913215937 R2:0.9141617585330128\n",
            "My Regression: RMSE 1273.9274722261964 R2:0.89978205624191\n"
          ]
        }
      ],
      "source": [
        "# Sklearn VS LinReg (best model in the world! :)\n",
        "sklearn_lin = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "weights = np.random.rand(X_train_scaled[0].size)\n",
        "my_lin = LinReg(gd_type = 'GradientDescent', w0 = weights)\n",
        "\n",
        "sklearn_lin = sklearn_lin.fit(X_train_scaled, y_train)\n",
        "my_lin = my_lin.fit(X_train_scaled, y_train)\n",
        "\n",
        "skl_pred = sklearn_lin.predict(X_test_scaled)\n",
        "my_pred = my_lin.predict(X_test_scaled)\n",
        "\n",
        "# RMSE\n",
        "skl_rmse = mean_squared_error(y_test, skl_pred, squared=False)\n",
        "my_rmse = mean_squared_error(y_test, my_pred, squared=False)\n",
        "# R2\n",
        "skl_r2 = r2_score(y_test, skl_pred)\n",
        "my_r2 = r2_score(y_test, my_pred)\n",
        "\n",
        "print(f'Linear Regression: RMSE {skl_rmse} R2:{skl_r2}')\n",
        "print(f'My Regression: RMSE {my_rmse} R2:{my_r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini Conclusions**\n",
        "\n",
        "The RMSE of the sklearn model is slightly smaller than that of our model, the R2 is higher for sklearn => Sklearn won the battle this time, BUT\n",
        "Our model is not completely terrible, as the results differ slightly))"
      ],
      "metadata": {
        "id": "MBBWy4-iSUnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "searcher = GridSearchCV(LinReg(), [{\"gd_type\": [\"Momentum\"], \"alpha\": [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0, 1, 1e1, 1e2]}], scoring = \"neg_root_mean_squared_error\", cv = 4)\n",
        "searcher.fit(X_train_scaled, y_train)\n",
        "best_alpha = searcher.best_params_[\"alpha\"]\n",
        "print(f'Alpha for Momentum: {best_alpha}')\n",
        "\n",
        "grad_iters = [250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250, 2500]\n",
        "searcher = GridSearchCV(LinReg(), [ {\"gd_type\": [\"GradientDescent\"], \"max_iter\": grad_iters}], scoring = \"neg_root_mean_squared_error\", cv = 4)\n",
        "searcher.fit(X_train_scaled, y_train)\n",
        "best_gd_iters = searcher.best_params_[\"max_iter\"]\n",
        "print(f'Full GD iterations: {best_gd_iters}')\n",
        "print(grad_iters)\n",
        "\n",
        "searcher = GridSearchCV(LinReg(), [ {\"gd_type\": [\"StochasticDescent\"], \"max_iter\": grad_iters, \"delta\": [0.3]}], scoring = \"neg_root_mean_squared_error\", cv = 4)\n",
        "searcher.fit(X_train_scaled, y_train)\n",
        "best_sgd_iters = searcher.best_params_[\"max_iter\"]\n",
        "print(f'SGD iterations: {best_sgd_iters}')\n",
        "\n",
        "searcher = GridSearchCV(LinReg(), [{ \"gd_type\": [\"Momentum\"], \"alpha\": [best_alpha], \"max_iter\": grad_iters}], scoring = \"neg_root_mean_squared_error\", cv = 4)\n",
        "searcher.fit(X_train_scaled, y_train)\n",
        "best_m_iters = searcher.best_params_[\"max_iter\"]\n",
        "print(f'Momentum iterations = {best_m_iters}')\n",
        "\n",
        "searcher = GridSearchCV(LinReg(), [{ \"gd_type\": [\"Adagrad\"], \"alpha\": [best_alpha], \"max_iter\": grad_iters}], scoring = \"neg_root_mean_squared_error\", cv = 4)\n",
        "searcher.fit(X_train_scaled, y_train)\n",
        "best_ad_iters = searcher.best_params_[\"max_iter\"]\n",
        "print(f'Adagrad iterations = {best_ad_iters}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVnMdpr-SVBU",
        "outputId": "46e41109-4019-41fd-cc2f-fe1fd1a06ab7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha for Momentum: 0.1\n",
            "Full GD iterations: 2500\n",
            "[250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250, 2500]\n",
            "SGD iterations: 2500\n",
            "Momentum iterations = 2500\n",
            "Adagrad iterations = 2250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make conclusions**\n",
        "\n",
        "The more iterations = the better\n",
        "\n",
        "Best alpha = 0.1"
      ],
      "metadata": {
        "id": "oMyCuA0mhnQs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aODs45unnJN7"
      },
      "source": [
        "#### 8. [1 points] Plot graphs (on the same picture) of the dependence of the loss function value on the iteration number for Full GD, SGD, Momentum and Adagrad. Draw conclusions about the rate of convergence of various modifications of gradient descent.\n",
        "\n",
        "Don't forget about what *beautiful* graphics should look like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "C_BqE4elnJN7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "c76c756e-8411-4e64-985e-cf971216dfe3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "weights = np.random.rand(X_train_scaled[0].size)\n",
        "gd = LinReg(gd_type = 'GradientDescent', w0 = weights, max_iter = best_gd_iters)\n",
        "trained_gd = gd.fit(X_train_scaled, y_train)\n",
        "\n",
        "sgd = LinReg(gd_type='StochasticDescent', w0 = weights, max_iter = best_sgd_iters, delta = 0.3)\n",
        "trained_sgd = gd.fit(X_train_scaled, y_train)\n",
        "\n",
        "momentum = LinReg(gd_type = 'Momentum', w0 = weights, max_iter = best_m_iters, alpha = best_alpha)\n",
        "trained_momentum = gd.fit(X_train_scaled, y_train)\n",
        "\n",
        "adagrad = LinReg(gd_type = 'Adagrad', w0 = weights, max_iter = best_ad_iters)\n",
        "trained_adagrad = gd.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.plot(trained_gd.loss_history[:100], label='gradient', color = 'red')\n",
        "plt.plot(trained_sgd.loss_history[:100], label='stochastic', color = 'blue')\n",
        "plt.plot(trained_momentum.loss_history[:100], label = 'momentum', color = 'yellow')\n",
        "plt.plot(trained_adagrad.loss_history[:100], label = 'adagrad', color = 'orange')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make conclusions**\n",
        "\n",
        "All methods lead to a ~fast decrease in the values of the loss function\n",
        "\n",
        "And they behave about the same\n"
      ],
      "metadata": {
        "id": "bNOcR8ouU1iX"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}